{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Representations (BM_25) : Sentence-Document  Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "\n",
    "# --- NLTK PACKAGE ---\n",
    "import nltk\n",
    "# Tokenizers\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, PunktSentenceTokenizer, RegexpTokenizer\n",
    "# Stemming and Lemmatizing\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "# Stopwords\n",
    "from nltk.corpus import stopwords, state_union, brown, movie_reviews, treebank\n",
    "\n",
    "# --- GENSIM PACKAGE ---\n",
    "import gensim, logging\n",
    "from gensim.models import Word2Vec, doc2vec, Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_json('squad_train_doc.json')\n",
    "data_train.rename(columns={'passages': 'documents'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segregating Data to form a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>questions</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Architecturally, the school has a Catholic ch...</td>\n",
       "      <td>[[What is the Grotto at Notre Dame?, To whom d...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ ...</td>\n",
       "      <td>[[In what city and state did Beyonce  grow up?...</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Montana i/mɒnˈtænə/ is a state in the Western...</td>\n",
       "      <td>[[What is its rank in popularion?, What is the...</td>\n",
       "      <td>Montana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The phrase \"in whole or in part\" has been sub...</td>\n",
       "      <td>[[Which phrase is especially contentious withi...</td>\n",
       "      <td>Genocide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The emergence of resistance of bacteria to an...</td>\n",
       "      <td>[[What is the purpose of antibiotic treatment?...</td>\n",
       "      <td>Antibiotics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  [Architecturally, the school has a Catholic ch...   \n",
       "1  [Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ ...   \n",
       "2  [Montana i/mɒnˈtænə/ is a state in the Western...   \n",
       "3  [The phrase \"in whole or in part\" has been sub...   \n",
       "4  [The emergence of resistance of bacteria to an...   \n",
       "\n",
       "                                           questions                     title  \n",
       "0  [[What is the Grotto at Notre Dame?, To whom d...  University_of_Notre_Dame  \n",
       "1  [[In what city and state did Beyonce  grow up?...                   Beyoncé  \n",
       "2  [[What is its rank in popularion?, What is the...                   Montana  \n",
       "3  [[Which phrase is especially contentious withi...                  Genocide  \n",
       "4  [[What is the purpose of antibiotic treatment?...               Antibiotics  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_compact_dataframe():\n",
    "    context_list = []\n",
    "    question_list = []\n",
    "    for doc in data_train.documents:\n",
    "        context_list.append(get_each_context_each_questionSet(doc)[0])\n",
    "        question_list.append(get_each_context_each_questionSet(doc)[1])\n",
    "    return context_list, question_list\n",
    "\n",
    "def get_each_context_each_questionSet(document):\n",
    "    each_doc_context_list = [document[i]['context'] for i in range(len(document))]\n",
    "    each_doc_question_list = [document[i]['questions'] for i in range(len(document))]\n",
    "    return  each_doc_context_list, each_doc_question_list\n",
    "\n",
    "context_list, question_list = get_compact_dataframe()[0], get_compact_dataframe()[1]\n",
    "dataframe = pd.DataFrame({'title':data_train.title, 'context':context_list, 'questions': question_list})\n",
    "list_all_context_per_doc = [' '.join(context_list[i]) for i in range(len(context_list))]\n",
    "list_all_questions_per_doc = [sum(question_list[i],[]) for i in range(len(question_list))]\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "tokenized_context_and_questions = []\n",
    "\n",
    "for context, question in zip(list_all_context_per_doc, list_all_questions_per_doc):\n",
    "    context_words = [word for word in word_tokenize(context) if word not in stop_words]\n",
    "    question_words = [word for word in word_tokenize(' '.join(question)) if word not in stop_words]\n",
    "    tokenized_context_and_questions.append(context_words + question_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BM25 MODEL\n",
    "''' Accepts a list of tokenized words of context plus questions as its training data.\n",
    "'''\n",
    "BM_25_model = gensim.summarization.bm25.BM25(tokenized_context_and_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#BM_25_model.save('bm25.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model_loaded = gensim.models.Doc2Vec.load('bm25.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence - Document Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = 'What is Grotto at Notre Dame?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Score_BM25</th>\n",
       "      <th>Rank_BM25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>21.450317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Hanover</td>\n",
       "      <td>9.429974</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Paris</td>\n",
       "      <td>9.163790</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Gothic_architecture</td>\n",
       "      <td>7.794399</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Dominican_Order</td>\n",
       "      <td>7.794269</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Universal_Studios</td>\n",
       "      <td>7.792825</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>To_Kill_a_Mockingbird</td>\n",
       "      <td>7.792561</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>Humanism</td>\n",
       "      <td>7.790938</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Appalachian_Mountains</td>\n",
       "      <td>7.788856</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2008_Summer_Olympics_torch_relay</td>\n",
       "      <td>6.652963</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Document  Score_BM25  Rank_BM25\n",
       "0            University_of_Notre_Dame   21.450317          1\n",
       "132                           Hanover    9.429974          2\n",
       "327                             Paris    9.163790          3\n",
       "237               Gothic_architecture    7.794399          4\n",
       "287                   Dominican_Order    7.794269          5\n",
       "55                  Universal_Studios    7.792825          6\n",
       "12              To_Kill_a_Mockingbird    7.792561          7\n",
       "435                          Humanism    7.790938          8\n",
       "340             Appalachian_Mountains    7.788856          9\n",
       "21   2008_Summer_Olympics_torch_relay    6.652963         10"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BM25(query).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Accepts a question(query) to implement BM 25 Model.\n",
    "    Takes a query and word tokenizes it. \n",
    "          'get_scores' - Calculates the similarity distance between the tokenized-query and the document.\n",
    "    \n",
    "    --> Returns a dataframe with Document name, Score and Rank\n",
    "'''\n",
    "def BM25(query):    \n",
    "    scores = BM_25_model.get_scores(query.split(),1)\n",
    "    BM25_dataframe = pd.DataFrame({'Document':data_train.title, 'Score_BM25':scores}).sort_values(by=['Score_BM25'],ascending=False)\n",
    "    BM25_dataframe['Rank_BM25'] = [i for i in range(1, len(data_train.title)+1)]\n",
    "    return BM25_dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
